{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ee1621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T14:31:56.432447Z",
     "iopub.status.busy": "2022-11-02T14:31:56.431752Z",
     "iopub.status.idle": "2022-11-02T14:32:00.941729Z",
     "shell.execute_reply": "2022-11-02T14:32:00.940674Z"
    },
    "papermill": {
     "duration": 4.518034,
     "end_time": "2022-11-02T14:32:00.944190",
     "exception": false,
     "start_time": "2022-11-02T14:31:56.426156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "from collections import deque\n",
    "#from tensorflow import set_random_seed\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "seed=1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "from collections import deque\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794bdb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T14:32:00.956124Z",
     "iopub.status.busy": "2022-11-02T14:32:00.954343Z",
     "iopub.status.idle": "2022-11-02T14:32:00.965598Z",
     "shell.execute_reply": "2022-11-02T14:32:00.964753Z"
    },
    "papermill": {
     "duration": 0.018002,
     "end_time": "2022-11-02T14:32:00.967574",
     "exception": false,
     "start_time": "2022-11-02T14:32:00.949572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelupload',\n",
       " 'pytorch-model',\n",
       " 'aug-model',\n",
       " 'modelres50',\n",
       " 'more-vids',\n",
       " 'test-video3',\n",
       " 'test-video1',\n",
       " 'new-model',\n",
       " 'alb-model',\n",
       " 'test-video',\n",
       " 'test-video2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ffa1878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T14:32:00.974996Z",
     "iopub.status.busy": "2022-11-02T14:32:00.974703Z",
     "iopub.status.idle": "2022-11-02T14:32:00.978762Z",
     "shell.execute_reply": "2022-11-02T14:32:00.977690Z"
    },
    "papermill": {
     "duration": 0.010423,
     "end_time": "2022-11-02T14:32:00.981116",
     "exception": false,
     "start_time": "2022-11-02T14:32:00.970693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('../input/modelupload/resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9733e04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T14:32:00.988194Z",
     "iopub.status.busy": "2022-11-02T14:32:00.987937Z",
     "iopub.status.idle": "2022-11-02T14:32:02.863867Z",
     "shell.execute_reply": "2022-11-02T14:32:02.862907Z"
    },
    "papermill": {
     "duration": 1.882231,
     "end_time": "2022-11-02T14:32:02.866421",
     "exception": false,
     "start_time": "2022-11-02T14:32:00.984190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f909da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T14:32:02.875550Z",
     "iopub.status.busy": "2022-11-02T14:32:02.874114Z",
     "iopub.status.idle": "2022-11-02T14:33:26.833450Z",
     "shell.execute_reply": "2022-11-02T14:33:26.832423Z"
    },
    "papermill": {
     "duration": 83.966089,
     "end_time": "2022-11-02T14:33:26.835828",
     "exception": false,
     "start_time": "2022-11-02T14:32:02.869739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting omnixai\r\n",
      "  Downloading omnixai-1.2.2-py3-none-any.whl (512 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from omnixai) (0.37.1)\r\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from omnixai) (1.3.5)\r\n",
      "Requirement already satisfied: scikit-learn<1.2,>=0.24 in /opt/conda/lib/python3.7/site-packages (from omnixai) (1.0.2)\r\n",
      "Collecting SALib\r\n",
      "  Downloading SALib-1.4.5-py2.py3-none-any.whl (756 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.6/756.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from omnixai) (0.8.10)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from omnixai) (1.7.3)\r\n",
      "Requirement already satisfied: pillow<10.0 in /opt/conda/lib/python3.7/site-packages (from omnixai) (9.1.1)\r\n",
      "Requirement already satisfied: lime in /opt/conda/lib/python3.7/site-packages (from omnixai) (0.2.0.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from omnixai) (21.3)\r\n",
      "Requirement already satisfied: scikit-image>=0.17.2 in /opt/conda/lib/python3.7/site-packages (from omnixai) (0.19.3)\r\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (from omnixai) (7.33.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from omnixai) (4.64.0)\r\n",
      "Requirement already satisfied: statsmodels>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from omnixai) (0.13.2)\r\n",
      "Requirement already satisfied: shap>=0.40.0 in /opt/conda/lib/python3.7/site-packages (from omnixai) (0.41.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from omnixai) (0.3.5.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from omnixai) (3.5.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from omnixai) (1.21.6)\r\n",
      "Collecting hnswlib>=0.5.0\r\n",
      "  Downloading hnswlib-0.6.2.tar.gz (31 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.0->omnixai) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.0->omnixai) (2022.1)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.17.2->omnixai) (2021.11.2)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.17.2->omnixai) (1.3.0)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.17.2->omnixai) (2.5)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.17.2->omnixai) (2.19.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->omnixai) (3.0.9)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2,>=0.24->omnixai) (1.0.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2,>=0.24->omnixai) (3.1.0)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from shap>=0.40.0->omnixai) (0.55.2)\r\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.7/site-packages (from shap>=0.40.0->omnixai) (0.0.7)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from shap>=0.40.0->omnixai) (2.1.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.10.1->omnixai) (0.5.2)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (0.7.5)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (0.1.3)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (2.12.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (3.0.30)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (0.18.1)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (5.1.1)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (0.2.0)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (59.8.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (4.8.0)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython->omnixai) (5.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->omnixai) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->omnixai) (4.33.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->omnixai) (1.4.3)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from SALib->omnixai) (4.12.0)\r\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from SALib->omnixai) (0.2.9)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython->omnixai) (0.8.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->omnixai) (4.3.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels>=0.10.1->omnixai) (1.15.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython->omnixai) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->omnixai) (0.2.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->SALib->omnixai) (3.8.0)\r\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->shap>=0.40.0->omnixai) (0.38.1)\r\n",
      "Requirement already satisfied: pox>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pathos->SALib->omnixai) (0.3.1)\r\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /opt/conda/lib/python3.7/site-packages (from pathos->SALib->omnixai) (1.7.6.5)\r\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /opt/conda/lib/python3.7/site-packages (from pathos->SALib->omnixai) (0.70.13)\r\n",
      "Building wheels for collected packages: hnswlib\r\n",
      "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.6.2-cp37-cp37m-linux_x86_64.whl size=2162573 sha256=b0c2a3bfe28842ac5cf958c0759363f02a1dd4006fe672f59b097be3a6f765f7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/01/80/9805daef8cd398ceb20003af220f77c4689cab8e43d466481b\r\n",
      "Successfully built hnswlib\r\n",
      "Installing collected packages: hnswlib, SALib, omnixai\r\n",
      "Successfully installed SALib-1.4.5 hnswlib-0.6.2 omnixai-1.2.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting kaleido\r\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: kaleido\r\n",
      "Successfully installed kaleido-0.2.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (5.10.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly) (8.0.1)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install omnixai\n",
    "!pip  install -U kaleido\n",
    "!pip install plotly\n",
    "import json\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "from omnixai.data.image import Image\n",
    "from omnixai.explainers.vision.specific.gradcam.pytorch.gradcam import GradCAM\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\"\n",
    "from IPython.display import display # to display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5cf9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T14:33:26.857712Z",
     "iopub.status.busy": "2022-11-02T14:33:26.856688Z",
     "iopub.status.idle": "2022-11-02T14:33:26.863058Z",
     "shell.execute_reply": "2022-11-02T14:33:26.862136Z"
    },
    "papermill": {
     "duration": 0.019207,
     "end_time": "2022-11-02T14:33:26.865023",
     "exception": false,
     "start_time": "2022-11-02T14:33:26.845816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#img = Image(PilImage.open('dataset/test/normal/6_12600.jpg').convert('RGB'))\n",
    "# Load the class names\n",
    "# The preprocessing model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    #transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "preprocess = lambda ims: torch.stack([transform(im.to_pil()) for im in ims])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fbbae43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T14:33:26.885495Z",
     "iopub.status.busy": "2022-11-02T14:33:26.885223Z",
     "iopub.status.idle": "2022-11-02T14:33:32.646526Z",
     "shell.execute_reply": "2022-11-02T14:33:32.645498Z"
    },
    "papermill": {
     "duration": 5.774081,
     "end_time": "2022-11-02T14:33:32.648850",
     "exception": false,
     "start_time": "2022-11-02T14:33:26.874769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load('../input/alb-model/pytorch_res18_alb.pth')\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0948fdb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T14:33:32.671461Z",
     "iopub.status.busy": "2022-11-02T14:33:32.671164Z",
     "iopub.status.idle": "2022-11-02T14:36:11.126395Z",
     "shell.execute_reply": "2022-11-02T14:36:11.124686Z"
    },
    "papermill": {
     "duration": 158.468602,
     "end_time": "2022-11-02T14:36:11.128740",
     "exception": false,
     "start_time": "2022-11-02T14:33:32.660138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gettyimages-1187122876-640_adpp.mp4\n",
      "25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:1033: UserWarning:\n",
      "\n",
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 28.37891936302185 682\n",
      "gettyimages-1421601676-640_adpp.mp4\n",
      "29.970030000612258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 31.624539136886597 1027\n",
      "gettyimages-1354415227-640_adpp.mp4\n",
      "29.97002997002997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 10.574640274047852 352\n",
      "gettyimages-1194009882-640_adpp.mp4\n",
      "30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 23.76591157913208 750\n",
      "gettyimages-1326673030-640_adpp.mp4\n",
      "29.97002997002997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 17.83919405937195 598\n",
      "gettyimages-1309159036-640_adpp.mp4\n",
      "29.97002997002997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 38.46069121360779 1270\n",
      "gettyimages-1372117402-640_adpp.mp4\n",
      "23.976023976023978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 7.611642360687256 244\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "\n",
    "CLASSES = {0:\"Collapsed Building\", 1:\"Fire\", 2:\"Flood\", 3:\"Normal\"}\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = (224, 224)\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "\n",
    "preprocess = lambda ims: torch.stack([TRANSFORM_IMG(im.to_pil()) for im in ims])\n",
    "explainer = GradCAM(\n",
    "    model=model,\n",
    "    target_layer=model.layer4[-1],\n",
    "    preprocess_function=preprocess\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = torch.load('../input/pytorch-model/pytorch_res18.pth')\n",
    "model.to(device)\n",
    "#model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "#model.eval()\n",
    "\n",
    "\n",
    "\n",
    "for i in os.listdir('../input/test-video3/'):\n",
    "    print(i)\n",
    "    videoCapture = cv2.VideoCapture(\"../input/test-video3/\"+i)\n",
    "    fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "    print(fps)\n",
    "    size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "    ps = 25\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    videoWriter = cv2.VideoWriter(str(i)+\"_out.mp4\", fourcc, fps, size)\n",
    "    Q = deque(maxlen=int(fps))\n",
    "    #with torch.no_grad():\n",
    "    t1 = time.time()\n",
    "    c=0\n",
    "    success, frame = videoCapture.read()\n",
    "    while success:\n",
    "        c+=1\n",
    "        frame_copy = copy.deepcopy(frame) \n",
    "        frame_copy = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2RGB)\n",
    "        image_gc = Image(copy.deepcopy(frame_copy))\n",
    "\n",
    "\n",
    "        # Explain the top label\n",
    "        explanations = explainer.explain(image_gc)\n",
    "        #print(explanations)\n",
    "\n",
    "        image_tensor = TRANSFORM_IMG(frame_copy)\n",
    "\n",
    "        image_tensor = image_tensor.unsqueeze(0) \n",
    "        test_input = image_tensor.to(device)\n",
    "        outputs = model(test_input)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probability =  F.softmax(outputs, dim=1)\n",
    "        top_probability, top_class = probability.topk(1, dim=1)\n",
    "        predicted = predicted.cpu().detach().numpy()\n",
    "        predicted = predicted.tolist()[0]\n",
    "        Q.append(predicted)\n",
    "\n",
    "        results = np.array(Q).mean(axis=0)\n",
    "        #i = np.argmax(results)\n",
    "        #print(Q, results, CLASSES[np.round(results)])\n",
    "        label =CLASSES[np.round(results)]\n",
    "        top_probability = top_probability.cpu().detach().numpy()\n",
    "        top_probability = top_probability.tolist()[0][0]\n",
    "        percentage = top_probability\n",
    "        top_probability = '%.2f%%' % (top_probability * 100)\n",
    "        if percentage < 0.45:\n",
    "            label=\"Normal\"\n",
    "#         if label == 'Normal':\n",
    "#             color = (0, 150, 0)\n",
    "#         else:\n",
    "#             color = (0, 0, 150)\n",
    "#         frame = cv2.putText(frame, label+': '+top_probability, (50, 50), 2, 0.5 ,color, 1 )\n",
    "\n",
    "        heatmap = explanations.explanations[0]['scores']\n",
    "        heatmap = cv2.resize(heatmap, (frame.shape[1], frame.shape[0]))\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        superimposed_img  = cv2.addWeighted(heatmap, 0.3, frame, 0.5, 0)\n",
    "        #plt.imshow(frame+heatmap)\n",
    "        #print(superimposed_img.shape)\n",
    "        if label is \"Normal\":\n",
    "            color = (0, 150, 0)\n",
    "            frame = cv2.putText(frame, label+': '+top_probability, (50, 50), 2, 0.5 ,color, 1 )\n",
    "            videoWriter.write(frame)\n",
    "        else:\n",
    "            color = (0, 0, 150)\n",
    "            superimposed_img = cv2.putText(superimposed_img, label+': '+top_probability, (50, 50), 2, 0.5 ,color, 1 )\n",
    "            videoWriter.write(superimposed_img)\n",
    "\n",
    "\n",
    "        \n",
    "        success, frame = videoCapture.read()\n",
    "    videoWriter.release()\n",
    "    \n",
    "    t2=time.time()\n",
    "    print('done', t2-t1, c)\n",
    "                                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a085f",
   "metadata": {
    "papermill": {
     "duration": 0.010265,
     "end_time": "2022-11-02T14:36:11.150143",
     "exception": false,
     "start_time": "2022-11-02T14:36:11.139878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c43e61",
   "metadata": {
    "papermill": {
     "duration": 0.010103,
     "end_time": "2022-11-02T14:36:11.171042",
     "exception": false,
     "start_time": "2022-11-02T14:36:11.160939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ab5b8",
   "metadata": {
    "papermill": {
     "duration": 0.010264,
     "end_time": "2022-11-02T14:36:11.191556",
     "exception": false,
     "start_time": "2022-11-02T14:36:11.181292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09494a",
   "metadata": {
    "papermill": {
     "duration": 0.010088,
     "end_time": "2022-11-02T14:36:11.211887",
     "exception": false,
     "start_time": "2022-11-02T14:36:11.201799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0194ef1",
   "metadata": {
    "papermill": {
     "duration": 0.01011,
     "end_time": "2022-11-02T14:36:11.232476",
     "exception": false,
     "start_time": "2022-11-02T14:36:11.222366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 266.399326,
   "end_time": "2022-11-02T14:36:14.960882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-02T14:31:48.561556",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
