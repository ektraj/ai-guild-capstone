{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDENTIFYING DISASTER IN AERIAL IMAGERY\n",
    "This solution builds an aerial image classification model which when embedded on a drone can identify calamities such as collapsed buildings, flood, or fire with high confidence. This solution can  autonomously monitor a disaster-stricken area and alert in real-time.\n",
    "\n",
    "## Why is this important?\n",
    "Government authorities face following challenges at the event of a disaster :\n",
    "- Poor intersectoral coordination\n",
    "- Lack of an early warning system\n",
    "- Slow response from the relief agencies\n",
    "- Lack of trained / dedicated search and rescue teams\n",
    "\n",
    "## What impact can it have?\n",
    "- Governments can coordinate better disaster relief programs.\n",
    "- Enhanced situational awareness\n",
    "- Access to early warnings and verified reports in real-time.\n",
    "- Capable of operating in remote and difficult to access areas.\n",
    "- Faster mitigation of impact on environment and human population\n",
    "- Protection of life and property from prolonged damage\n",
    "- Deloitte can pitch this solution to GPS industry \n",
    "to help government manage disaster response program effectively\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:46:24.437076Z",
     "iopub.status.busy": "2022-12-01T10:46:24.436424Z",
     "iopub.status.idle": "2022-12-01T10:47:23.902047Z",
     "shell.execute_reply": "2022-12-01T10:47:23.901451Z",
     "shell.execute_reply.started": "2022-12-01T10:46:24.437007Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "torch.manual_seed(17)\n",
    "from pandas.core.common import flatten\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "random.seed(0)\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\"\n",
    "from PIL import Image as PilImage\n",
    "from omnixai.data.image import Image\n",
    "from omnixai.explainers.vision.specific.gradcam.pytorch.gradcam import GradCAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#       Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:47:23.903651Z",
     "iopub.status.busy": "2022-12-01T10:47:23.903235Z",
     "iopub.status.idle": "2022-12-01T10:47:23.910548Z",
     "shell.execute_reply": "2022-12-01T10:47:23.909905Z",
     "shell.execute_reply.started": "2022-12-01T10:47:23.903632Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224),\n",
    "        A.OneOf([\n",
    "            A.IAAAffine(scale=1.0, translate_percent=0.2, translate_px=None, rotate=0.0, shear=0.0, order=1, cval=0, mode='reflect', always_apply=False, p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.1,0.2), contrast_limit=(-0.1, 0.2), p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomCrop(width=200, height=200),\n",
    "            A.CLAHE(p=0.3),\n",
    "            \n",
    "            #A.GridDistortion(p=0.3),\n",
    "            A.SafeRotate(limit=90, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n",
    "            ], p=0.75),\n",
    "        A.Resize(224,224),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        \n",
    "        \n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#       Create Train, Valid and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:15.923287Z",
     "iopub.status.busy": "2022-12-01T10:48:15.922638Z",
     "iopub.status.idle": "2022-12-01T10:48:16.003076Z",
     "shell.execute_reply": "2022-12-01T10:48:16.002543Z",
     "shell.execute_reply.started": "2022-12-01T10:48:15.923262Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = 'dataset/train/' \n",
    "train_image_paths = [] #to store image paths in list\n",
    "classes = [] #to store class values\n",
    "\n",
    "\n",
    "# get all the paths from train_data_path and append image paths and class to to respective lists\n",
    "\n",
    "for data_path in glob.glob(train_data_path + '/*'):\n",
    "    classes.append(data_path.split('/')[-1]) \n",
    "    train_image_paths.append(glob.glob(data_path + '/*'))\n",
    "    \n",
    "for data_path in glob.glob(val_data_path + '/*'):\n",
    "    train_image_paths.append(glob.glob(data_path + '/*'))\n",
    "     \n",
    "    \n",
    "train_image_paths = list(flatten(train_image_paths))\n",
    "random.shuffle(train_image_paths)\n",
    "\n",
    "print('train_image_path example: ', train_image_paths[0])\n",
    "print('class example: ', classes[0])\n",
    "\n",
    "# split train valid test from train paths (70,20, 10)\n",
    "train_image_paths, valid_image_paths, test_image_paths = train_image_paths[:int(0.7*len(train_image_paths))],train_image_paths[int(0.7*len(train_image_paths)):int(0.9*len(train_image_paths))],train_image_paths[int(0.9*len(train_image_paths)):]\n",
    "test_image_paths = list(flatten(test_image_paths))\n",
    "print(\"Train size: {}\\nValid size: {}\\nTest size: {}\".format(len(train_image_paths), len(valid_image_paths), len(test_image_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:16.678841Z",
     "iopub.status.busy": "2022-12-01T10:48:16.678590Z",
     "iopub.status.idle": "2022-12-01T10:48:16.683630Z",
     "shell.execute_reply": "2022-12-01T10:48:16.683004Z",
     "shell.execute_reply.started": "2022-12-01T10:48:16.678823Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#      Create dictionary for class indexes\n",
    "#######################################################\n",
    "idx_to_class = {i:j for i, j in enumerate(sorted(classes))}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:17.418200Z",
     "iopub.status.busy": "2022-12-01T10:48:17.417568Z",
     "iopub.status.idle": "2022-12-01T10:48:17.422768Z",
     "shell.execute_reply": "2022-12-01T10:48:17.422324Z",
     "shell.execute_reply.started": "2022-12-01T10:48:17.418180Z"
    }
   },
   "outputs": [],
   "source": [
    "class DisasterDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = image_filepath.split('/')[-2]\n",
    "        label = class_to_idx[label]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = DisasterDataset(train_image_paths,train_transforms)\n",
    "valid_dataset = DisasterDataset(valid_image_paths,train_transforms) #test transforms are applied\n",
    "test_dataset = DisasterDataset(test_image_paths,test_transforms)\n",
    "\n",
    "image_datasets=dict()\n",
    "image_datasets['train'] = train_dataset\n",
    "image_datasets['val'] = valid_dataset\n",
    "image_datasets['test'] = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:18.886052Z",
     "iopub.status.busy": "2022-12-01T10:48:18.885798Z",
     "iopub.status.idle": "2022-12-01T10:48:18.890209Z",
     "shell.execute_reply": "2022-12-01T10:48:18.889753Z",
     "shell.execute_reply.started": "2022-12-01T10:48:18.886032Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "input_size=224\n",
    "batch_size = 8\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:19.719638Z",
     "iopub.status.busy": "2022-12-01T10:48:19.719007Z",
     "iopub.status.idle": "2022-12-01T10:48:20.313281Z",
     "shell.execute_reply": "2022-12-01T10:48:20.312738Z",
     "shell.execute_reply.started": "2022-12-01T10:48:19.719613Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                  Visualize Dataset\n",
    "#         Images are plotted after augmentation\n",
    "#######################################################\n",
    "\n",
    "def visualize_augmentations(dataset, idx=0, samples=10, cols=5, random_img = False):\n",
    "    \n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    #we remove the normalize and tensor conversion from our augmentation pipeline\n",
    "    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    rows = samples // cols\n",
    "    \n",
    "        \n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 8))\n",
    "    for i in range(samples):\n",
    "        if random_img:\n",
    "            idx = np.random.randint(1,len(train_image_paths))\n",
    "        image, lab = dataset[idx]\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "        ax.ravel()[i].set_title(idx_to_class[lab])\n",
    "    plt.tight_layout(pad=1)\n",
    "    plt.show()    \n",
    "\n",
    "visualize_augmentations(train_dataset,np.random.randint(1,len(train_image_paths)), random_img = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:22.026509Z",
     "iopub.status.busy": "2022-12-01T10:48:22.025926Z",
     "iopub.status.idle": "2022-12-01T10:48:22.034158Z",
     "shell.execute_reply": "2022-12-01T10:48:22.033677Z",
     "shell.execute_reply.started": "2022-12-01T10:48:22.026487Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                  Train function\n",
    "#            to learn and update weights\n",
    "#######################################################\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # keeping-track-of-losses \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_acc = []\n",
    "    valid_acc = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss =  100\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "      \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step(epoch_loss)\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc.detach().cpu().numpy() )\n",
    "                \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                valid_losses.append(epoch_loss)\n",
    "                valid_acc.append(epoch_acc.detach().cpu().numpy() )\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_loss:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "\n",
    "    return model, train_losses, valid_losses, train_acc, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:24.992657Z",
     "iopub.status.busy": "2022-12-01T10:48:24.992348Z",
     "iopub.status.idle": "2022-12-01T10:48:25.623692Z",
     "shell.execute_reply": "2022-12-01T10:48:25.623122Z",
     "shell.execute_reply.started": "2022-12-01T10:48:24.992636Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#        load resnet18 backbone and add a new dense layer\n",
    "##########################################################\n",
    "\n",
    "model_ft = models.resnet18(weights=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:35.441732Z",
     "iopub.status.busy": "2022-12-01T10:48:35.440991Z",
     "iopub.status.idle": "2022-12-01T10:48:38.730778Z",
     "shell.execute_reply": "2022-12-01T10:48:38.730109Z",
     "shell.execute_reply.started": "2022-12-01T10:48:35.441702Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define Loss function, Optimizer and Learning Rate\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.00001, momentum=0.9)\n",
    "# Find learning rate in a cyclic manner\n",
    "exp_lr_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.00001, max_lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T10:48:38.732509Z",
     "iopub.status.busy": "2022-12-01T10:48:38.731887Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_ft, train_losses, valid_losses, train_acc, valid_acc = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T12:07:54.476960Z",
     "iopub.status.busy": "2022-11-29T12:07:54.476583Z",
     "iopub.status.idle": "2022-11-29T12:07:54.714793Z",
     "shell.execute_reply": "2022-11-29T12:07:54.713943Z",
     "shell.execute_reply.started": "2022-11-29T12:07:54.476935Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#                 visualize loss vs epochs\n",
    "##########################################################\n",
    "    \n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format = 'retina'\n",
    "    \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(valid_losses, label='Validation loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(frameon=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T12:08:04.559234Z",
     "iopub.status.busy": "2022-11-29T12:08:04.558871Z",
     "iopub.status.idle": "2022-11-29T12:08:04.758586Z",
     "shell.execute_reply": "2022-11-29T12:08:04.757512Z",
     "shell.execute_reply.started": "2022-11-29T12:08:04.559207Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#                 visualize accuracy vs epochs\n",
    "##########################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(valid_acc, label='Validation Accuracy')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T16:16:44.105259Z",
     "iopub.status.busy": "2022-11-30T16:16:44.104481Z",
     "iopub.status.idle": "2022-11-30T16:16:51.072105Z",
     "shell.execute_reply": "2022-11-30T16:16:51.071238Z",
     "shell.execute_reply.started": "2022-11-30T16:16:44.105236Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#               Evaluate model on test data\n",
    "##########################################################\n",
    "\n",
    "dl_test = torch.utils.data.DataLoader(image_datasets['test'], batch_size=dataset_sizes['test'],\n",
    "                                             shuffle=False, num_workers=4)\n",
    "\n",
    "# Get a batch of test data\n",
    "true = []\n",
    "pred = []\n",
    "for i in  range(1):\n",
    "    test_input , classes= next(iter(dl_test))\n",
    "    true.extend(classes.tolist())\n",
    "    test_input = test_input.to(device)\n",
    "    outputs = model_ft(test_input)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    probability =  F.softmax(outputs, dim=1)\n",
    "\n",
    "    top_probability, top_class = probability.topk(1, dim=1)\n",
    "\n",
    "    predicted = predicted.cpu().detach().numpy()\n",
    "    pred.extend(predicted)\n",
    "    predicted = predicted.tolist()[0]\n",
    "\n",
    "    label = idx_to_class[predicted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T16:17:25.056158Z",
     "iopub.status.busy": "2022-11-30T16:17:25.055335Z",
     "iopub.status.idle": "2022-11-30T16:17:25.062692Z",
     "shell.execute_reply": "2022-11-30T16:17:25.062288Z",
     "shell.execute_reply.started": "2022-11-30T16:17:25.056133Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#             Generate Classification Report\n",
    "##########################################################\n",
    "\n",
    "target_names = ['collapsed_building', 'fire', 'flood', 'normal']\n",
    "print(classification_report(true, pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Model\n",
    "\n",
    "This is to save the model once trained and load the trained model for future evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T11:45:31.402914Z",
     "iopub.status.busy": "2022-11-29T11:45:31.401978Z",
     "iopub.status.idle": "2022-11-29T11:45:32.425154Z",
     "shell.execute_reply": "2022-11-29T11:45:32.424124Z",
     "shell.execute_reply.started": "2022-11-29T11:45:31.402885Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#                     Save  model\n",
    "##########################################################\n",
    "torch.save(model_ft, 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T16:16:36.870031Z",
     "iopub.status.busy": "2022-11-30T16:16:36.869870Z",
     "iopub.status.idle": "2022-11-30T16:16:39.528580Z",
     "shell.execute_reply": "2022-11-30T16:16:39.528034Z",
     "shell.execute_reply.started": "2022-11-30T16:16:36.870031Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#                   Load  saved  model\n",
    "##########################################################\n",
    "model_ft = torch.load('trained_model.pth')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
